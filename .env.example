# AI Provider Configuration (for extract-entities.js script)
# ================================================

# Choose your AI provider: 'lmstudio', 'openai', or 'fal'
AI_PROVIDER=fal

# ────────────────────────────────────────────────────────────
# FAL AnyLLM Configuration (RECOMMENDED - cost-effective & powerful)
# ────────────────────────────────────────────────────────────

# Your FAL API key (required if using fal provider)
# Get your key at: https://fal.ai/dashboard/keys
FAL_KEY=your-fal-key-here

# FAL model to use (via fal-ai/any-llm endpoint powered by OpenRouter)
# Available models (check https://fal.ai/models/fal-ai/any-llm/api for latest):
#   - meta-llama/llama-3.1-70b-instruct (DEFAULT) - Excellent quality, cost-effective
#   - meta-llama/llama-3.1-8b-instruct - Faster, good quality
#   - google/gemini-2.5-flash - Fast and cost-effective
#   - anthropic/claude-3.5-sonnet - Premium quality (10x cost)
FAL_MODEL=meta-llama/llama-3.1-70b-instruct

# ────────────────────────────────────────────────────────────
# OpenAI Configuration (Alternative - excellent quality)
# ────────────────────────────────────────────────────────────

# Your OpenAI API key (required if using openai provider)
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI model to use
# RECOMMENDED OPTIONS:
#   - gpt-4o-mini (DEFAULT) - Excellent quality, cost-effective (~$0.15/M input tokens)
#   - gpt-4o - Best quality, more expensive (~$2.50/M input tokens)
#   - gpt-3.5-turbo - Faster, cheaper, but less accurate
OPENAI_MODEL=gpt-4o-mini

# ────────────────────────────────────────────────────────────
# LM Studio Configuration (Local alternative - free)
# ────────────────────────────────────────────────────────────

# LM Studio server URL (default: http://localhost:1234)
LM_STUDIO_URL=http://localhost:1234

# LM Studio model to use
# Download models from: https://lmstudio.ai
# RECOMMENDED: mistralai/mistral-nemo-12b
LM_STUDIO_MODEL=mistralai/mistral-nemo-12b

# Optional: API token if LM Studio has authentication enabled
# LM_API_TOKEN=your_token_here
